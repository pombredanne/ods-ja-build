\chapter{ヒープ}
\chaplabel{heaps}
優先度付きキューは利用価値がとても高い。
この章では、優先度付きキューの実装を2つ説明する。
いずれの実装も特殊な二分木であり、\emph{ヒープ（heap）}と呼ばれている。
\ejindex{heap}{ひーぷ@ヒープ}%
\ejindex{binary heap}{にぶんひーぷ@二分ヒープ}%
\ejindex{heap!binary}{ひーぷ@ヒープ!にぶん@二分}%
ヒープには「雑多に積まれたもの」という意味がある。
これは「高度に構造化されて積み上げられたもの」であった二分探索木とは対照的である。

1つめのヒープの実装では、完全二分木をシミュレートするのに配列を使う。
この実装は極めて高速であり、ヒープソート（\secref{heapsort}参照）という整列アルゴリズムを実装できる。
ヒープソートは既知の整列アルゴリズムの中で最速なもののひとつである。
2つめに紹介する実装では、完全二分木に限らず、より柔軟な二分木を扱う。
この実装では、優先度付きキューの要素すべてを別の優先度付きキューに取り込む操作を利用する。 % TODO: YJ meld操作は定義されておらず、代わりにmerge操作がある。しかしデータ構造の名前はMeldableHeapなのでどうしたものか。 <- spinute: ここで関数名を見せとくメリットも特になさそうなので、meld は消しました

\section{#BinaryHeap#：二分木を間接的に表現する} % YJ: Implicitは非明示的の方がよいかな
% XXX: この implicit は https://en.wikipedia.org/wiki/Implicit_data_structure のキモチが入っていたりしないか。この意味の implicit には訳語がなさそう
% 「非明示的」という非日常用語を使うとなると、なんらかの定義が必要になります。以降の原文での使われ方をみると、定義語としてでなく、配列という（木だと思うと）implicitな形で木を表すという日常的な意味のようです。「二分木を間接的に表す」がよいとおもいます -kshikano
\seclabel{binaryheap}

\index{BinaryHeap@#BinaryHeap#}%
1つめに紹介する優先度付きキューの実装は、400年以上前に発見された\emph{Eytzinger法}という手法に基づく。
\ejindex{Eytzinger's method}{Eytzingerの方法}%
この手法により、木のノードを幅優先順（\secref{bintree:traversal}）に配列に入れていくことで、完全二分木を表現できる。
具体的には、配列の添字0の位置に木の根を、添字1の位置に根の左の子を、添字2の位置に根の右の子を、添字3の位置に根の左の子の左の子を格納していく（\figref{eytzinger}）。

\begin{figure}
  \begin{center}
    \includegraphics[scale=0.90909]{figs/eytzinger}
  \end{center}
  \caption{Eytzinger法により、配列を使って完全二分木を表現する}
  \figlabel{eytzinger}
\end{figure}

大きな木に対してEytzinger法を適用すると規則性が見えてくる。
添字#i#のノードの左の子は添字$#left(i)#=2#i#+1$の位置に入り、右の子は添字$#right(i)#=2#i#+2$の位置に入る。
添字#i#のノードの親は、添字$#parent(i)#=(#i#-1)/2$の位置にある。
\codeimport{ods/BinaryHeap.left(i).right(i).parent(i)}

#BinaryHeap#では、この手法を使うことで、要素が\emph{ヒープ順（heap order）}に並んだ間接的な形で完全二分木を表す。
\ejindex{heap-ordered binary tree}{ひーぷじゅんにぶんぎ@ヒープ順二分木}%
\ejindex{binary tree!heap-ordered}{にぶんぎ@二分木!ひーぷじゅん@ヒープ順}%
\ejindex{heap order}{ひーぷじゅん@ヒープ順}%
ヒープ順とは、添字#i#（$#i#=0$）の位置に格納されている値が、添字#parent(i)#に格納されている値以上であるような順番である。
したがって#BinaryHeap#では、優先度付きキューにおける最小値が添字0の位置、つまり根に格納されていることになる。

#BinaryHeap#では#n#個の要素を配列#a#に格納する。
\codeimport{ods/BinaryHeap.a.n}

#add(x)#の実装は簡単である。
他の配列ベースのデータ構造と同じく、まずは#a#が一杯かどうかを確認する
（$#a.length#=#n#$かどうかを確認する）。
もしそうなら#a#を拡張する。
続いて#x#を#a[n]#に入れ、#n#を1増やす。
あとはヒープ性（要素がヒープ順に並んでいること）を保てばよい。% YJ: ヒープ性はヒープ順が保たれていること？ <- spinute: 少し上で定義しているヒープ順に要素が並んでいることが、heap property を満たしていることと同じ意味なのだと思います
これは、#x#とその親とを交換する操作を、#x#が親以上になるまで繰り返せばよい
（\figref{heap-insert}）。
\codeimport{ods/BinaryHeap.add(x).bubbleUp(i)}

\begin{figure}
  \begin{center}
    \includegraphics[height=\QuarterHeightScaleIfNeeded]{figs/heap-insert-1} \\
    \includegraphics[height=\QuarterHeightScaleIfNeeded]{figs/heap-insert-2} \\
    \includegraphics[height=\QuarterHeightScaleIfNeeded]{figs/heap-insert-3} \\
    \includegraphics[height=\QuarterHeightScaleIfNeeded]{figs/heap-insert-4} \\
  \end{center}
  \caption{#BinaryHeap#に値6を追加する}
  \figlabel{heap-insert}
\end{figure}

#remove()#は、ヒープから最小の値を削除する。この操作の実装には少し工夫が必要になる。
根が最小値であることはわかっているのだが、これを削除したあともヒープ性が成り立つことを保証しなければならない。

最も簡単な方法は、根と#a[n-1]#を交換し、交換後に#a[n-1]#にある値を削除して、#n#を1小さくすることだ。
しかし、結果として新しく根となった値は、おそらく最小値ではない。
そこで、これを下方向に動かしていく必要がある。
新しく根となった要素を2つの子と比較し、
新しく根となった要素の値が3つのうちで最小ならば処理を終了する。
そうでないなら、2つの子のうち小さいものと入れ替え、同様の処理を繰り返す。
\codeimport{ods/BinaryHeap.remove().trickleDown(i)}

\begin{figure}
  \begin{center}
    \includegraphics[height=\QuarterHeightScaleIfNeeded]{figs/heap-remove-1} \\
    \includegraphics[height=\QuarterHeightScaleIfNeeded]{figs/heap-remove-2} \\
    \includegraphics[height=\QuarterHeightScaleIfNeeded]{figs/heap-remove-3} \\
    \includegraphics[height=\QuarterHeightScaleIfNeeded]{figs/heap-remove-4} \\
  \end{center}
  \caption{#BinaryHeap#から最小の値4を削除する}
  \figlabel{heap-remove}
\end{figure}

他の配列ベースのデータ構造と同様に、#resize()#のための時間は無視することにする。
#resize()#の時間は\lemref{arraystack-amortized}の償却解析において考慮されるからだ。
すると、#add(x)#と#remove()#の実行時間は、配列によって間接的に表されている二分木の高さに依存する。
この二分木は、都合がいいことに、\emph{完全}二分木である。
\ejindex{binary tree!complete}{にぶんぎ@二分木!かんぜん@完全}%
\ejindex{complete binary tree}{かんぜんにぶんぎ@完全二分木}%
どの深さにも、最下層を除いて、その層で取りうる個数のノードが含まれている。% levelの良い訳語はあるか？ / 「層」でよいと思いました -kshikano
よって、$h$を木の高さとすると、この木には少なくとも$2^h$個のノードがある。
言い換えると、次の式が成り立つ。
\[
  #n# \ge 2^h
\]
両辺の対数を取ると、次の式が成り立つ。
\[
   h \le \log #n#
\]
以上より、#add(x)#と#remove()#の実行時間はいずれも$O(\log #n#)$である。

\subsection{要約}

次の定理に#BinaryHeap#の性能をまとめる。

\begin{thm}\thmlabel{binaryheap}
  #BinaryHeap#は、優先度付きキューのインターフェースを実装する。
  #BinaryHeap#は#add(x)#と#remove()#をサポートする。#resize()#のコストを無視すると、いずれの操作の実行時間も$O(\log #n#)$である。

  空の#BinaryHeap#から、$m$個の#add(x)#操作および#remove()#操作からなる任意の列を実行する。このとき、すべての#resize()#にかかる時間の合計は$O(m)$である。
\end{thm}

\section{#MeldableHeap#：つなぎ合わせられるランダムなヒープ}
\seclabel{meldableheap}
% XXX: meldableは定訳がある? % YJ: Introduction to Algorithmsにあるので日本語版を確認すればあるはず -- spinute: （mergeable heap は載っているけど）meldable heap は載ってない気がする。ひとまず meldable のままにしておきます。

\index{MeldableHeap@#MeldableHeap#}%
この節では#MeldableHeap#を紹介する。
#MeldableHeap#も#BinaryHeap#と同じく優先度付きキューの実装であり、背後にある構造もヒープである。
しかし、#BinaryHeap#と違って、要素数から二分木の形が一意には決まらない。#MeldableHeap#では、背後にある二分木の形状に制約がない。

#MeldableHeap#における#add(x)#および#remove()#は、#merge(h1,h2)#という操作を使って実装される。
この操作は、ヒープのノード#h1#と#h2#を引数とし、#h1#を根とする部分木と#h2#を根とする部分木のすべてのノードを含むヒープの根を返す。

#merge(h1,h2)#は再帰的に定義できる（\figref{meldable-merge}）。
#h1#または#h2#が#nil#なら、単に#h2#と#h1#をそれぞれ返せばよい。
そうでない場合について考える。一般性を失うことなく、$#h1.x# \le #h2.x#$の場合について考えればよい。
この場合、新たなヒープの根の値は#h1.x#である。
続いて、#h2#を#h1.left#か#h1.right#のどちらかと再帰的に併合する。
ここでランダム性の出番だ。
コインを投げ、#h2#を#h1.left#と#h1.right#のどちらと併合するかを決める。
\codeimport{ods/MeldableHeap.merge(h1,h2)}

\begin{figure}
  \centering{\includegraphics[width=\ScaleIfNeeded]{figs/meldable-merge}}
  \caption{#h1#と#h2#を併合するために、#h1.left#または#h1.right#のいずれかに#h2#を併合する}
  \figlabel{meldable-merge}
\end{figure}

#merge(h1,h2)#の実行時間については、期待値が$O(\log #n#)$であることを次節で示す。
ここで、#n#は#h1#と#h2#の要素数の合計である。

#merge(h1,h2)#を使えば、#add(x)#は簡単に実装できる。
#x#を含む新たなノード#u#を作り、#u#をヒープの根と併合すればよい。
\codeimport{ods/MeldableHeap.add(x)}
このとき、実行時間の期待値は$O(\log (#n#+1)) = O(\log #n#)$である。

#remove()#も同様に簡単に実装できる。
削除したいのは根なので、その2つの子を併合し、その結果を新たな根とすればよい。
\codeimport{ods/MeldableHeap.remove()}
このときも実行時間の期待値は$O(\log #n#)$である。

実行時間の期待値が$O(\log #n#)$である#MeldableHeap#の操作は、このほかにもいくつかある。
例えば次のような操作がある。
\begin{itemize}
\item #remove(u)#：ノード#u#をヒープから削除する
\item #absorb(h)#：ヒープに#h#の要素をすべて追加し、#h#を空にする % TODO: YJ これはmeld(h)? -- spinute: 章冒頭の記述にあった meld(h) のことなら、meld は absorb ではなく merge の書き間違いで、absorb とは関係ないのでははないでしょうか。僕はこのままであっているのではないかと思っています
\end{itemize}
いずれの操作も、定数回の#merge(h1,h2)#を使って実装できる。

\subsection{#merge(h1,h2)#の解析}

#merge(h1,h2)#は、二分木におけるランダムウォークを考えることで解析できる。
二分木における\emph{ランダムウォーク}は、根から出発する。
各ステップでコインを投げ、その結果に応じて、いまいるノードから右の子もしくは左の子に進む。
木からはみ出したら、つまり、進んだ先が#nil#になったら、処理を終了する。

次の補題は、二分木の形状にかかわらず成り立つという点で注目に値する。

\begin{lem}\lemlabel{tree-random-walk}
#n#個のノードからなる二分木におけるランダムウォークの長さの期待値は#\log (n+1)#以下である。
\end{lem}

\begin{proof}
#n#に関する帰納法により証明する。
$#n#=0$のとき、ステップ数は$0=\log (#n#+1)$である。
以下では、任意の非負整数$#n#'< #n#$について、示したい補題が成り立つと仮定する。

$#n#_1$を左の部分木の大きさとする。
このとき、$#n#_2=#n#-#n#_1-1$が右の部分木の大きさである。
根から出発して一歩進み、大きさ$#n#_1$の部分木または$#n#_2$の部分木の処理へと進む。
$#n#_1$と$#n#_2$はいずれも$#n#$より小さいので、帰納法の仮定より、ステップ数の期待値は次のようになる。
% XXX: 原著では等号になっているが、仮定は不等号ではないか -- Pat に確認します。
\[
    \E[W] \le 1 + \frac{1}{2}\log (#n#_1+1) + \frac{1}{2}\log (#n#_2+1)
\]
$\log$は上に凸な関数なので、$\E[W]$は$#n#_1=#n#_2=(#n#-1)/2$で最大値を取る。
よって、ランダムウォークのステップ数の期待値は次のようになる。
\begin{align*}
    \E[W]
% XXX: ここも上と同様（原著では等号になっている）-- Pat に確認します。
   & \le 1 + \frac{1}{2}\log (#n#_1+1) + \frac{1}{2}\log (#n#_2+1) \\
   & \le  1 + \log ((#n#-1)/2+1) \\
   & =  1 + \log ((#n#+1)/2) \\
   & =  \log (#n#+1)  \enspace \qedhere
\end{align*}
\end{proof}

なお、情報理論では、\lemref{tree-random-walk}をエントロピーの用語を使って証明できる。
\begin{proof}[\lemref{tree-random-walk}の情報理論的な証明]
$d_i$を、添字$i$に対応する外部ノード（#nil#）の深さとする。
#n#個のノードを持つ二分木が#n+1#個の外部ノードを持つことを思い出そう。
ランダムウォークが$i$番めの外部ノードに辿り着く確率は$p_i=1/2^{d_i}$である。
よって、ランダムウォークのステップ数の期待値は次のように計算できる。
\[
   H=\sum_{i=0}^{#n#} p_id_i
    =\sum_{i=0}^{#n#} p_i\log\left(2^{d_i}\right)
    = \sum_{i=0}^{#n#}p_i\log({1/p_i})
\]
右辺は、$#n#+1$個の要素にわたって確率分布のエントロピーを求めたものだとわかるだろう。
$#n#+1$個の要素にわたる確率分布のエントロピーに関する基本的な事実として、この値は$\log(#n#+1)$を超えない。
よって、補題が示された。
\end{proof}

ランダムウォークに関するこの結果より、#merge(h1,h2)#の実行時間の期待値は$O(\log #n#)$であることを示せる。

\begin{lem}
  #h1#および#h2#は2つのヒープの根であり、それぞれのヒープは$#n#_1$個および$#n#_2$個のノードを含むとする。
  このとき、#merge(h1,h2)#の実行時間は$O(\log #n#)$以下である。
  ただし、$#n#=#n#_1+#n#_2$である。
\end{lem}

\begin{proof}
#merge#の各ステップでは、ランダムウォークを1ステップ実行し、#h1#か#h2#のいずれかを根とする部分木に進む。
このアルゴリズムは、2つのランダムウォークのどちらか一方が木からはみ出して$#h1#=#null#$または$#h2#=#null#$になったら終了する。
よって、併合アルゴリズムのステップ数の期待値は次の値以下である。
  \[
     \log (#n#_1+1) + \log (#n#_2+1) \le 2\log #n# \qedhere
  \]
\end{proof}

\subsection{要約}

次の定理に#MeldableHeap#の性能をまとめる。

\begin{thm}\thmlabel{meldableheap}
  #MeldableHeap#は、優先度付きキューのインターフェースを実装する。
  #MeldableHeap#は、#add(x)#と#remove()#をサポートする。いずれの操作も、実行時間の期待値は$O(\log #n#)$である。
\end{thm}

\section{ディスカッションと練習問題}

完全二分木を配列またはリストとして間接的に表現する方法を最初に提案したのはEytzinger\cite{e1590}であると考えられてきた。
彼は、貴族の家系図が記された書物でこの手法を使った。
\ejindex{pedigree family tree}{かけいず@家系図}%
この章で説明した#BinaryHeap#は、Williamsが最初に提案したものである\cite{w64}。

この章で説明した、ランダム性を利用した#MeldableHeap#は、GambinとMalinowskiが最初に提案したものである\cite{gm98}。
同様なデータ構造はほかにもいくつか知られている。
leftist heaps \cite[Section~5.3.2]{c72,k97v3}、
\ejindex{leftist heap}{leftist heap}%
\ejindex{heap!leftist}{ひーぷ@ヒープ!leftist}%
binomial heaps \cite{v78}、
\ejindex{binomial heap}{にこうひーぷ@二項ヒープ}%
\ejindex{heap!binomial}{ひーぷ@ヒープ!にこう@二項}%
Fibonacci heaps \cite{ft87}、
\ejindex{Fibonacci heap}{ふぃぼなっちひーぷ@フィボナッチヒープ}%
\ejindex{heap!Fibonacci}{ひーぷ@ヒープ!ふぃぼなっち@フィボナッチ}%
pairing heaps \cite{fsst86}、
\ejindex{pairing heap}{pairing heap}%
\ejindex{heap!pairing}{ひーぷ@ヒープ!pairing}%
skew heaps \cite{st83}などである。
\ejindex{skew heap}{skew heap}%
\ejindex{heap!skew}{ひーぷ@ヒープ!skew}%
しかし、いずれも#MeldableHeap#ほどシンプルではない。

これらのデータ構造の中には、#decreaseKey(u,y)#という操作をサポートするものもある。
\index{decreaseKey@#decreaseKey(u,y)#}%
これはノード#u#に格納される値を小さくして#y#とする操作である
（$#y#\le#u.x#$であることを前提とする）。
これらのデータ構造の大部分では、このような操作のためにノード#u#を削除して#y#を追加するので、$O(\log #n#)$の時間がかかる。
しかし、もっと効率的にこの操作を実装できるデータ構造もある。
中でも、Fibonacci heapsは、$O(1)$の償却実行時間で#decreaseKey(u,y)#を実行できる。
pairing heapsの特殊なものでは、$O(\log\log #n#)$の償却実行時間で#decreaseKey(u,y)#を実行できる\cite{e09}。
効率的な#decreaseKey(u,y)#は、ダイクストラ法など、グラフアルゴリズムの高速化に役立つ
\cite{ft87}。

\begin{exc}
  \figref{heap-insert}に示した#BinaryHeap#に7と3を順に追加する様子を図示せよ。
\end{exc}

\begin{exc}
\figref{heap-remove}に示した#BinaryHeap#から次の2つの値（6と8）を順に削除する様子を図示せよ。
\end{exc}

\begin{exc}
  #remove(i)#を実装せよ。
  これは#BinaryHeap#における#a[i]#の値を削除するメソッドである。
  このメソッドの実行時間は$O(\log #n#)$でなければならない。
  また、なぜこのメソッドが役に立ちそうにないかを説明せよ。
\end{exc}

\begin{exc}\exclabel{general-eytzinger}
  \ejindex{tree!$d$-ary}{き@木!$d$-aray}%
  $d$分木は二分木の一般化である。
  これは各内部ノードが$d$個の子を持つ木である。
  Eytzingerの方法を使えば、完全$d$分木も配列を使って表現できる。
  添字#i#が与えられたとき、#i#の親と、#i#の$d$個の子、それぞれの添字を計算する方法を与えよ。
\end{exc}

\begin{exc}
  \index{DaryHeap@#DaryHeap#}%
  \excref{general-eytzinger}で学んだことを使って\emph{#DaryHeap#}を設計、実装せよ。
  これは$d$分木版の#BinaryHeap#である。
  #DaryHeap#の操作の実行時間を解析し、#DaryHeap#の性能を#BinaryHeap#と比較せよ。
\end{exc}

\begin{exc}
  \figref{meldable-merge}に示した#MeldableHeap#に17、82を順に追加する様子を図示せよ。
  ランダムなビットが必要なときにはコイン投げを使うこと。
\end{exc}

\begin{exc}
  \figref{meldable-merge}に示した#MeldableHeap#から、次の2つの値（4と8）を削除せよ。
  ランダムなビットが必要なときにはコイン投げを使うこと。
\end{exc}

\begin{exc}
#MeldableHeap#からノード#u#を削除する#remove(u)#を実装せよ。
ただし、このメソッドの実行時間の期待値は$O(\log #n#)$でなければならない。
\end{exc}

\begin{exc}
#BinaryHeap#および#MeldableHeap#において2番めに小さい値を定数時間で見つける方法を示せ。
\end{exc}

\begin{exc}
#BinaryHeap#および#MeldableHeap#において#k#番めに小さい値を$O(#k#\log #k#)$の時間で見つける方法を示せ。
（ヒント：別のヒープを使ってみよう。）
\end{exc}

\begin{exc}
#k#個の整列済みリストであって、合計の長さが#n#であるものがあるとき、ヒープを使ってこれらのリストを1つの整列済みリストにする方法を示せ。
このとき、実行時間は$O(#n#\log #k#)$でなければならない。
（ヒント：$#k#=2$の場合から考えてみよう。）
\end{exc}
